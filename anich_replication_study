#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sat Nov 23 13:24:59 2019

@author: ianich
"""

import pandas as pd
import numpy as np
from sklearn.datasets import make_regression
from scipy.stats import f

#Create test data w/ known coefficients
X, y, coef = make_regression(n_samples = 1000, n_features = 10, coef = True)
test_data = pd.DataFrame(X)
control_vars = []
for i in range(len(test_data.columns)):
    control_vars.append(f'control_{i}')
test_data.columns = pd.Series(control_vars)
test_data.insert(0, 'outcome', y)
test_data_coef = pd.DataFrame(
        coef,
        columns = ['coefficient',],
        index = control_vars,
)

#Create OLS regression class
class Regression():
    def __init__(self, dataframe):
        self.dataframe = dataframe.copy()
        self.intercept = None
        self.control_names = None
        self.outcomes = None
        self.controls = None
        self.instruments = None
        self.endog = None
        self.y = None
        self.X = None
        self.n = None
        self.k = None
        self.G = None
        self.res = None
        self.coef = None
        self.y_fitted = None
        self.x_fitted = None
        self.se = None
        self.cluster_se = None
        self.HC1 = None
        self.cluster_HC1 = None
        self.r2 = None
        self.groups = None
        self.nk_check = None
        self.pmc_check = None
    
    def ols(self, outcomes, controls, intercept = True):
        self.control_names = controls[:]
        if intercept:
            self.intercept = True
            self.dataframe.insert(0, 'intercept', 1)
            self.control_names.append('intercept')
        self.outcomes = self.dataframe[outcomes]
        self.controls = self.dataframe[self.control_names]
        self.y = np.matrix(self.outcomes.values).T
        self.X = np.matrix(self.controls.values)
        self.n = self.X.shape[0]
        self.k = self.X.shape[1]
        if self.n < self.k:
            self.nk_check = False
        else:
            self.nk_check = True
        try:
            (self.X.T*self.X).I
            self.pmc_check = True
        except Exception as e:
            self.pmc_check = e
        #test invertability of (X'X)^-1
        if self.pmc_check != True:
            print(f'error: {self.pmc_check}')
        elif self.nk_check == False:
            print('error: number of observations < number of controls')            
        else:
            X = self.X
            y = self.y
            n = self.n
            k = self.k
            
            #use matrix methods to run OLS
            B = (X.T*X).I*X.T*y
            self.coef = pd.DataFrame(
                    B,
                    columns = ['coefficient',],
                    index = self.controls.columns,
            )
            
            P = X*(X.T*X).I*X.T
            y_hat = P*y
            self.y_fitted = y_hat
            
            M = (np.identity(n)-P)
            e_hat = M*y
            self.res = e_hat
            
            #calculate HC1 covariance matrix estimator/standard errors
            XtDX = 0
            for i in range(n):
                x = X[i]
                e = e_hat[i,0]
                e2 = e*e
                product = x.T*x*e2
                XtDX += product
            self.HC1 = (n/(n-k))*(X.T*X).I*XtDX*(X.T*X).I
            se = [np.sqrt(self.HC1[i,i]) for i in range(k)]
            self.se = pd.DataFrame(
                    se, 
                    columns = ['Standard Errors (HC1)'],
                    index = self.controls.columns,
            )
            #calculate R-squared
            sse = 0
            for i in range(n):
                square = self.res[i,0]**2
                sse += square
            mdsquare = 0
            y_mean = self.outcomes.mean()
            for i in range(n):
                y = reg.outcomes[i]
                square = (y - y_mean)**2
                mdsquare += square
            r2 = 1 - (sse/mdsquare)
            self.r2 = r2
            
    def cluster_ols(self, outcomes, controls, grouping_var, intercept = True):
        self.ols(outcomes, controls, intercept = True)
        if self.pmc_check == True and self.nk_check == True:
            #calculate cluster robust HC1/standard errors
            self.groups = {}
            for group in self.dataframe[grouping_var].unique():
                all_vars = list(self.controls.columns)
                all_vars.append(self.outcomes.name)
                group_df = self.dataframe.loc[
                        self.dataframe[grouping_var] == group,
                        all_vars,
                ].copy()
                self.groups[f'{group}'] = group_df
            n = self.n
            k = self.k
            G = len(self.groups)
            self.G = G
            Omega_hat = np.zeros((k,k))
            #for loop for Omega_hat summation
            for group, group_df in self.groups.items():
                X = np.matrix(group_df[list(self.controls.columns)].values)
                y = np.matrix(group_df[self.outcomes.name].values).T
                try:
                    M = (np.identity(X.shape[0]) - X*(X.T*X).I*X.T)
                    e_hat = M*y
                    product = X.T*e_hat*e_hat.T*X
                    Omega_hat += product
                except Exception as e:
                    print(f'group: {group}\n', e)
            X = self.X
            a = ((n-1)/(n-k))*(G/(G-1))
            cluster_HC1 = a*(X.T*X).I*Omega_hat*(X.T*X).I
            self.cluster_HC1 = cluster_HC1
            cluster_se = [np.sqrt(self.cluster_HC1[i,i]) for i in range(k)]
            self.cluster_se = pd.DataFrame(
                    cluster_se, 
                    columns = ['Cluster Robust Standard Errors (HC1)'],
                    index = self.controls.columns,
            )
    
    def f_test(self, test_type, null_controls = None, var_to_analyze = None, grouping_var = None):
        if self.pmc_check != True:
            print('No stored data. Run a regression method first.')
        elif null_controls == None and (var_to_analyze == None and grouping_var == None):
            print('error: no test parameters specified')
        elif test_type == 'null':
            n = self.n
            k = self.k
            q = len(null_controls)
            #sum unrestricted residuals
            sse_ur = 0
            for i in range(n):
                square = self.res[i,0]**2
                sse_ur += square
            #create and sum restricted residuals
            restricted_controls = set(self.control_names)
            null_controls = set(null_controls)
            restricted_controls = restricted_controls - null_controls
            restricted_controls = list(restricted_controls)
            X_r = np.matrix(self.dataframe[restricted_controls].values)
            M_r = np.identity(n) - X_r*(X_r.T*X_r).I*X_r.T
            y = self.y
            res_r = M_r*y
            sse_r = 0
            for i in range(n):
                square = res_r[i,0]**2
                sse_r += square
            #calculate F-stat, p-value
            F = ((sse_r - sse_ur)/sse_ur)*((n-k)/q)
            p = 1 - f.cdf(F, q, n-k)
            return F, p
        elif test_type == 'anova':
            dataframe = self.dataframe[[var_to_analyze, grouping_var]].copy()
            N = self.n
            K = len(dataframe[grouping_var].unique())
            sample_mean = dataframe[var_to_analyze].mean()
            #calculate relevant sums
            gm_sm_sq_sum = 0
            in_group_sq_sum = 0
            for group in dataframe[grouping_var].unique():
                group_df = dataframe.loc[dataframe[grouping_var] == group]
                group_mean = group_df[var_to_analyze].mean()
                n_g = group_df[var_to_analyze].count()
                #for loop to sum in-group mean difference squared
                in_group_sq = 0
                for i, item in group_df[var_to_analyze].iteritems():
                    y = item
                    mean_dif_sq = (y - group_mean)**2
                    in_group_sq += mean_dif_sq
                in_group_sq_sum += in_group_sq
                #summimg size of group * (group mean - sample_mean)^2
                gm_sm_sq = n_g*((group_mean - sample_mean)**2)
                gm_sm_sq_sum += gm_sm_sq
            #calculate F-stat, p-value
            F = ((N-K)/(K-1))*(gm_sm_sq_sum/in_group_sq_sum)
            p = 1 - f.cdf(F, K-1, N-K)
            return F, p
            
            

reg = Regression(test_data)
reg.ols('outcome', control_vars, intercept = True)
print('ols\n', reg.coef, '\nR2\n', reg.r2)
print('\ndummy\n', test_data_coef) 
print(reg.se) 
F, p = reg.f_test(test_type = 'null', null_controls = ['control_0', 'control_1'])
print(f'\nF-stat: {F}\n', f'p_value: {p}')

#insert grouping variable if necessary
groups = [round(i, -2) for i in range(1, test_data.shape[0]+1)]
test_data.insert(0, 'groups', groups)
cluster_reg = Regression(test_data)
cluster_reg.cluster_ols(
        'outcome',
        control_vars,
        grouping_var = 'groups',
        intercept = True)
print('\ncluster\n', cluster_reg.coef)
print(cluster_reg.cluster_se)
F, p = cluster_reg.f_test(
        test_type = 'anova',
        var_to_analyze = 'control_0',
        grouping_var = 'groups'
)
print(f'\nF-stat: {F}\n', f'p_value: {p}')

